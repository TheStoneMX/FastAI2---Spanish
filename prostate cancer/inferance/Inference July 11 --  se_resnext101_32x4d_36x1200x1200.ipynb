{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2 import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.callback.fp16 import *\n",
    "\n",
    "import pretrainedmodels\n",
    "import skimage.io\n",
    "\n",
    "WINDOW_SIZE = 200\n",
    "STRIDE = 64\n",
    "K = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Path(\"../input/prostate-cancer-grade-assessment\")\n",
    "\n",
    "submission_test_path = \"../input/prostate-cancer-grade-assessment/train_images/\"\n",
    "sample = '../input/prostate-cancer-grade-assessment/sample_submission.csv'\n",
    "\n",
    "sub_df = pd.read_csv(sample)\n",
    "# test_df = pd.read_csv(source/f'test.csv')\n",
    "test_df = pd.read_csv(source/f'train.csv')\n",
    "test_df = test_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(image):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image                  numpy.array   multi-dimensional array of the form WxHxC\n",
    "    \n",
    "    Returns:\n",
    "        ratio_white_pixels     float         ratio of white pixels over total pixels in the image \n",
    "    \"\"\"\n",
    "    width, height = image.shape[0], image.shape[1]\n",
    "    num_pixels = width * height\n",
    "    \n",
    "    num_white_pixels = 0\n",
    "    \n",
    "    summed_matrix = np.sum(image, axis=-1)\n",
    "    # Note: A 3-channel white pixel has RGB (255, 255, 255)\n",
    "    num_white_pixels = np.count_nonzero(summed_matrix > 620)\n",
    "    ratio_white_pixels = num_white_pixels / num_pixels\n",
    "    \n",
    "    green_concentration = np.mean(image[1])\n",
    "    blue_concentration = np.mean(image[2])\n",
    "    \n",
    "    return ratio_white_pixels, green_concentration, blue_concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_best_regions(regions, k=16):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        regions -- list           list of 2-component tuples first component the region, \n",
    "                                             second component the ratio of white pixels\n",
    "                                             \n",
    "        k -- int -- number of regions to select\n",
    "    \"\"\"\n",
    "    regions = [x for x in regions if x[3] > 180 and x[4] > 180]\n",
    "    k_best_regions = sorted(regions, key=lambda tup: tup[2])[:k]\n",
    "    return k_best_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best_regions(coordinates, image, window_size=512):\n",
    "    regions = {}\n",
    "    for i, tup in enumerate(coordinates):\n",
    "        x, y = tup[0], tup[1]\n",
    "        regions[i] = image[x : x+window_size, y : y+window_size, :]\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patches(slide_path, window_size=200, stride=224, k=16):\n",
    "    \n",
    "    try:\n",
    "        image = skimage.io.MultiImage(slide_path)[1]\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return None, None, None\n",
    "    \n",
    "    image = np.array(image)\n",
    "    \n",
    "    max_width, max_height = image.shape[0], image.shape[1]\n",
    "    regions_container = []\n",
    "    i = 0\n",
    "    \n",
    "    while window_size + stride*i <= max_height:\n",
    "        j = 0\n",
    "        \n",
    "        while window_size + stride*j <= max_width:            \n",
    "            x_top_left_pixel = j * stride\n",
    "            y_top_left_pixel = i * stride\n",
    "            \n",
    "            patch = image[\n",
    "                x_top_left_pixel : x_top_left_pixel + window_size,\n",
    "                y_top_left_pixel : y_top_left_pixel + window_size,\n",
    "                :\n",
    "            ]\n",
    "            \n",
    "            ratio_white_pixels, green_concentration, blue_concentration = compute_statistics(patch)\n",
    "            \n",
    "            region_tuple = (x_top_left_pixel, y_top_left_pixel, ratio_white_pixels, green_concentration, blue_concentration)\n",
    "            regions_container.append(region_tuple)\n",
    "            \n",
    "            j += 1\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    k_best_region_coordinates = select_k_best_regions(regions_container, k=k)\n",
    "    k_best_regions = get_k_best_regions(k_best_region_coordinates, image, window_size)\n",
    "    \n",
    "    return image, k_best_region_coordinates, k_best_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Glue to one picture\n",
    "def glue_images_one(tiles, image_size=200, n_tiles=36):\n",
    "\n",
    "        idxes = list(range(n_tiles))\n",
    "\n",
    "        n_row_tiles = int(np.sqrt(n_tiles))\n",
    "        image = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n",
    "        \n",
    "        for h in range(n_row_tiles):\n",
    "            for w in range(n_row_tiles):\n",
    "                i = h * n_row_tiles + w\n",
    "    \n",
    "                if len(tiles) > idxes[i]:\n",
    "                    this_img = tiles[idxes[i]]\n",
    "                else:\n",
    "                    this_img = np.ones((image_size, image_size, 3)).astype(np.uint8) * 255\n",
    "                    \n",
    "                this_img = 255 - this_img\n",
    "                \n",
    "                h1 = h * image_size\n",
    "                w1 = w * image_size\n",
    "                image[h1:h1+image_size, w1:w1+image_size] = this_img\n",
    "\n",
    "        image = 255 - image\n",
    "        image = image.astype(np.uint8)\n",
    "        image = image.transpose(0, 1, 2)\n",
    "\n",
    "        return tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inf(df=test_df):\n",
    "\n",
    "    filename = f'{submission_test_path}/{df.image_id}.tiff' \n",
    "    _, _, best_regions = generate_patches(filename, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n",
    "    \n",
    "    glued_image = glue_images_one(tiles=best_regions, image_size=WINDOW_SIZE, n_tiles=K)\n",
    "\n",
    "    return tensor(glued_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
     ]
    }
   ],
   "source": [
    "blocks = ( ImageBlock,CategoryBlock)\n",
    "getters = [ get_inf, ColReader('isup_grade')]\n",
    "\n",
    "dBlock = DataBlock( blocks=blocks,\n",
    "                    getters=getters,\n",
    "                    item_tfms=Resize(1200),\n",
    "                    batch_tfms=[*aug_transforms(size=320, max_warp=0.0, max_rotate=0.0),\n",
    "                               Normalize.from_stats(*imagenet_stats)]) \n",
    "\n",
    "dls = dBlock.dataloaders(test_df, bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pretrainedmodels.se_resnext101_32x4d(pretrained='imagenet')\n",
    "\n",
    "children = list(m.children())\n",
    "head = nn.Sequential(nn.AdaptiveAvgPool2d(1), \n",
    "                    Flatten(), \n",
    "                    nn.Linear(children[-1].in_features, 6))\n",
    "\n",
    "model = nn.Sequential(nn.Sequential(*children[:-2]), head) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7fcf56d6c860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('1_320x320_july9_0.9898_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 4, 4, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 3, 0, 3, 0, 3])\n",
      "\n",
      "writing  submission file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(submission_test_path):\n",
    "        \n",
    "    print('doing predictions')\n",
    "    test_dl = dls.test_dl(test_df)\n",
    "    _,_, preds = learn.get_preds(dl=test_dl, with_decoded=True)\n",
    "    print(preds)\n",
    "    print()\n",
    "\n",
    "    print('writing  submission file')\n",
    "    test_df[\"isup_grade\"] = preds\n",
    "    sub = test_df[[\"image_id\",\"isup_grade\"]]\n",
    "    sub.to_csv('submission.csv', index=False)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.show_results(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"isup_grade\"] = preds\n",
    "sub = test_df[[\"image_id\",\"isup_grade\"]]\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
